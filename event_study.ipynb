{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6f376b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.api import OLS, add_constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0307163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xls = pd.ExcelFile('./bank_datastream0816.xlsx')\n",
    "for sheet_name in xls.sheet_names:\n",
    "    df = pd.read_excel(xls, sheet_name=sheet_name)\n",
    "    df.to_csv(f'{sheet_name}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc84986",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data=pd.read_csv(\"./share price daily.csv\")\n",
    "market_data=pd.read_csv(\"./market indices_daily.csv\")\n",
    "riskfree_data=pd.read_csv(\"./EONIA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b03318",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stock_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600f1711",
   "metadata": {},
   "outputs": [],
   "source": [
    "market_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935ee4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "event_date = '2020-03-27'\n",
    "estimation_window_start = -63  # Start of the estimation window\n",
    "estimation_window_end = -3     # End of the estimation window\n",
    "event_window_start = -3  #  days before the event\n",
    "event_window_end = 3     #  days after the event\n",
    "bankname = stock_data.iloc[0:0,1:]\n",
    "marketindex = market_data.iloc[0:0,1:]\n",
    "riskfreeindex = riskfree_data.iloc[0:0,1:]\n",
    "bank_list = bankname.columns[0:].tolist()  # Convert the first row of stock_data to a list\n",
    "market_list = marketindex.columns[0:].tolist() \n",
    "riskfree_list = riskfreeindex.columns[0:].tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f26dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bank_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c61120",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(market_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03e28b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(riskfree_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8c1453",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Column names:\", stock_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe50693e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up column names\n",
    "stock_data.columns = stock_data.columns.str.strip()\n",
    "market_data.columns = market_data.columns.str.strip()\n",
    "riskfree_data.columns = riskfree_data.columns.str.strip()\n",
    "\n",
    "# Convert 'Date' column to datetime\n",
    "date_column_name = 'Date'\n",
    "stock_data[date_column_name] = pd.to_datetime(stock_data[date_column_name])\n",
    "market_data[date_column_name] = pd.to_datetime(market_data[date_column_name])\n",
    "riskfree_data[date_column_name] = pd.to_datetime(riskfree_data[date_column_name])\n",
    "\n",
    "# Set Date as index if it's not already\n",
    "stock_data.set_index(date_column_name, inplace=True)\n",
    "market_data.set_index(date_column_name, inplace=True)\n",
    "riskfree_data.set_index(date_column_name, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a743550a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Columns in riskfree_data:\", riskfree_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e587b496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty DataFrame to store daily returns\n",
    "bank_daily_returns = pd.DataFrame()\n",
    "market_daily_returns = pd.DataFrame()\n",
    "\n",
    "selected_metric = 'EONIARATE'\n",
    "riskfree_data_series = pd.to_numeric(riskfree_data[selected_metric], errors='coerce')\n",
    "    \n",
    "# Iterate over each column to calculate daily returns\n",
    "for column in stock_data.columns:\n",
    "    if column != date_column_name:  # Skip the Date column\n",
    "        # Ensure the column data is numeric\n",
    "        stock_data[column] = pd.to_numeric(stock_data[column], errors='coerce')\n",
    "        \n",
    "        # Calculate daily returns for this column\n",
    "        bank_daily_returns[column] = stock_data[column].pct_change()\n",
    "      \n",
    "        # Calculate excess returns by subtracting the risk-free rate\n",
    "        bank_daily_returns[column] = bank_daily_returns[column] - riskfree_data_series\n",
    "\n",
    "# If the Date column was reset earlier, there's no need to add it back again\n",
    "if date_column_name not in bank_daily_returns.columns:\n",
    "    bank_daily_returns.reset_index(inplace=True)\n",
    "\n",
    "# Reorder columns so that Date appears first\n",
    "bank_daily_returns = bank_daily_returns[[date_column_name] + [col for col in bank_daily_returns.columns if col != date_column_name]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b806f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bank_daily_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03a815c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "market_daily_returns = pd.DataFrame(index=market_data.index)\n",
    "for column in market_data.columns:\n",
    "    if column != date_column_name:  # Skip the Date column\n",
    "        # Ensure the column data is numeric\n",
    "        market_data[column] = pd.to_numeric(market_data[column], errors='coerce')\n",
    "        \n",
    "        # Calculate daily returns for this column\n",
    "        market_daily_returns[column] = market_data[column].pct_change()\n",
    "        \n",
    "        # Calculate excess returns by subtracting the risk-free rate\n",
    "        market_daily_returns[column] = market_daily_returns[column] - riskfree_data_series\n",
    "        \n",
    "print(market_daily_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b3f5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two DataFrames on the Data column\n",
    "merged_data=pd.merge(bank_daily_returns, market_daily_returns, on=date_column_name, suffixes=('_stock', '_market'))\n",
    "print(merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49d6f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the estimation period \n",
    "estimation_start_date = pd.to_datetime(event_date) + pd.Timedelta(days=estimation_window_start)\n",
    "estimation_end_date = pd.to_datetime(event_date) + pd.Timedelta(days=estimation_window_end)\n",
    "\n",
    "# Define the event period \n",
    "event_start_date = pd.to_datetime(event_date) + pd.Timedelta(days=event_window_start)\n",
    "event_end_date = pd.to_datetime(event_date) + pd.Timedelta(days=event_window_end)\n",
    "\n",
    "# Filter estimation data\n",
    "\n",
    "estimation_data = merged_data[(merged_data[date_column_name] >= estimation_start_date) & (merged_data[date_column_name] <= estimation_end_date)]\n",
    "\n",
    "# Filter event data\n",
    "event_data = merged_data[(merged_data[date_column_name] >= event_start_date) & (merged_data[date_column_name]<= event_end_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2e3a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(estimation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd6ebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(estimation_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544bdb84",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Market model: Regress stock returns on market returns\n",
    "#STOXX EUROPE 50\n",
    "# Perform multivariate regression for all banks against the market indices\n",
    "stoxx = market_list[0]\n",
    "sp = market_list[1]\n",
    "\n",
    "\n",
    "# Perform OLS regression for each bank against the market indices\n",
    "results = {}\n",
    "cumulative_abnormal_returns = pd.DataFrame()\n",
    "\n",
    "for bank in bank_list:\n",
    "    X = estimation_data[stoxx]  # Independent variables (market returns)\n",
    "    X = add_constant(X)  # Add a constant (intercept)\n",
    "    y = estimation_data[bank]  # Dependent variable (bank returns)\n",
    "    \n",
    "    \n",
    "    model = OLS(y, X).fit()  # Fit the model\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Predict expected returns during the event window\n",
    "    event_data[f'Expected_{bank}'] = model.predict(add_constant(event_data[stoxx]))\n",
    "    \n",
    "    # Calculate abnormal returns\n",
    "    event_data[f'Abnormal_{bank}'] = event_data[bank] - event_data[f'Expected_{bank}']\n",
    "    \n",
    "    # Calculate cumulative abnormal returns (CAR)\n",
    "    event_data[f'CAR_{bank}'] = event_data[f'Abnormal_{bank}'].cumsum()\n",
    "    \n",
    "    # Save CAR\n",
    "    cumulative_abnormal_returns[f'CAR_{bank}'] = event_data[f'CAR_{bank}']\n",
    "   \n",
    "    # Calculate cumulative Average abnormal returns (CAAR)\n",
    "    average_caar = cumulative_abnormal_returns.mean()\n",
    "    \n",
    "\n",
    "    \n",
    "#     # Print the summary for each bank\n",
    "#     print(f\"Regression results for {bank}:\")\n",
    "#     print(model.summary())\n",
    "#     print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # Display the results\n",
    "print(\"Estimation Start Date:\", estimation_start_date)\n",
    "print(\"Estimation End Date:\", estimation_end_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691ac835",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(event_data[['Date'] + [f'Abnormal_{bank}' for bank in bank_list] + \n",
    "                       [f'CAR_{bank}' for bank in bank_list]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a09b8b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = None\n",
    "average_caar.index = average_caar.index.str.replace('CAR_', '')\n",
    "print(average_caar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3119d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_date = pd.to_datetime('2020-03-27')\n",
    "event_data['Date'] = pd.to_datetime(event_data['Date'], errors='coerce')\n",
    "event_data['days_from_event'] = (event_data['Date'] - event_date).dt.days\n",
    "\n",
    "windows = {\n",
    "    'CAAR (-1,+1)': (-1, 1),\n",
    "    'CAAR (-1,+3)': (-1, 3),\n",
    "    'CAAR (0,+1)': (0, 1),\n",
    "}\n",
    "caar_results = pd.DataFrame()\n",
    "# Assume event_data contains the columns: 'Bank Name', 'days_from_event', and 'Abnormal_Return'\n",
    "\n",
    "for label, (start, end) in windows.items():\n",
    "    # Filter data for the specified time window\n",
    "    window_data = event_data[(event_data['days_from_event'] >= start) & (event_data['days_from_event'] <= end)]\n",
    "    \n",
    "    # Calculate CAAR for each bank\n",
    "    caar_per_bank = {}\n",
    "    for bank in bank_list:\n",
    "        if bank in window_data.columns:\n",
    "            caar_per_bank[bank] = window_data[f'Abnormal_{bank}'].mean()\n",
    "\n",
    "    # Convert to DataFrame for merging\n",
    "    caar_per_bank_df = pd.DataFrame(list(caar_per_bank.items()), columns=['Bank', label])\n",
    "    \n",
    "    # Merge the results into the caar_results DataFrame\n",
    "    if caar_results.empty:\n",
    "        caar_results = caar_per_bank_df\n",
    "    else:\n",
    "        caar_results = pd.merge(caar_results, caar_per_bank_df, on='Bank', how='outer')\n",
    "        \n",
    "        # Convert CAAR results to percentages and format them to two decimal places\n",
    "for column in caar_results.columns[1:]:  # Skip the 'Bank' column\n",
    "    caar_results[column] = caar_results[column] * 100  # Convert to percentage\n",
    "    caar_results[column] = caar_results[column].apply(lambda x: f\"{x:.2f}%\")  # Format to two decimal places\n",
    "\n",
    "# Display the calculated CAAR results for each company\n",
    "print(caar_results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcfcd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path = './Complete_CAAR_Results_63_stoxx_EONIA.xlsx'\n",
    "caar_results.to_excel(output_file_path, index=False)\n",
    "\n",
    "output_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4d213b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_file_path = './Complete_CAAR_Results.xlsx'\n",
    "# caar_results.to_excel(output_file_path, index=False)\n",
    "\n",
    "# output_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f1e68e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d2896e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
